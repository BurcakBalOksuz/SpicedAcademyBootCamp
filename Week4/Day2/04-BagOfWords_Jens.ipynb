{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a5d74e-6f81-4f0e-bb98-bbe0d929d1f2",
   "metadata": {},
   "source": [
    "# Bag Of Words\n",
    "## S1: \"I LIKE it\"    \n",
    "## S2: \"I don't like it\"\n",
    "## S3: \"I like it a lot\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa2168-60c6-4e17-a06d-476dbf1242a3",
   "metadata": {},
   "source": [
    "||I|like|it|don't|a|lot|(I like)| (like it)|...|\n",
    "|--|--|--|--|--|--|--|--|--|--|\n",
    "|S1|1|1|1|0|0|0|1|1|..|\n",
    "|S2|1|1|1|1|0|0|0|1|..|\n",
    "|S3|1|1|1|0|1|1|1|1|..|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1cb722-0dcc-477e-8c9f-6be19252cb47",
   "metadata": {},
   "source": [
    "### Difficulties creating the matrix\n",
    "* Capitalization\n",
    "* Punctuation\n",
    "* Typos/Slang/Too many Spaces\n",
    "* Encoding (ASCII/utf-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5c719-f0cf-4ce6-b77d-efa35d33c3aa",
   "metadata": {},
   "source": [
    "### Difficulties with doc-term (feature) matrix\n",
    "Turn words into tokens\n",
    "* n-grams (2-gram = all possible pairs)\n",
    "* Stop words (very common words to leave out), e.g. \"a\" \"and\"\n",
    "* Stemming (use only the stem of words, cleaned -> clean)\n",
    "* Lemmatization (use language rules to simplify matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea972f90-e25d-4590-ac44-39436e528235",
   "metadata": {},
   "source": [
    "Package recommendation: `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c93327cf-68ef-4394-930f-b0c0dbb5f60d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be6abf6e-a5fb-4d0c-8cde-773c7aa68480",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_moby_dick = 'https://www.gutenberg.org/files/2701/old/moby10b.txt'\n",
    "url_sea_wolf = 'https://www.gutenberg.org/cache/epub/1074/pg1074.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612bdd15-ab50-4338-9a2b-30746b30f3f3",
   "metadata": {},
   "source": [
    "## File import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d0d30-14ad-4b64-b40e-1b10bb9edc7e",
   "metadata": {},
   "source": [
    "`i = 1\n",
    "1) 'sea'+str(i)+'.txt' -> sea1.txt\n",
    "2) f'sea{i}.txt' -> sea1.txt\n",
    "3) 'sea{}.txt'.format(i)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb396858-e5d6-4510-b47b-d720001a18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seawolf chapter 1-10\n",
    "seawolf_chapters = []\n",
    "for i in range(10):\n",
    "    with open(f'sea{i+1}.txt', 'r') as my_file:\n",
    "        seawolf_chapters.append(my_file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54128e51-045f-4613-b937-14b581a8449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mobydick chapter 1-10\n",
    "mobydick_chapters = []\n",
    "for i in range(10):\n",
    "    with open(f'moby{i+1}.txt', 'r') as my_file:\n",
    "        mobydick_chapters.append(my_file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "61e7c0c7-51c0-4240-bcdb-cd37919a26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import moby dick chapters 1-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2644aad-3566-4e7f-959e-83736f114c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for chapter in seawolf_chapters:\n",
    "    for sentence in chapter:\n",
    "        corpus.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25ae5a63-7b6b-424a-b769-ea66a2fd5f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3038"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten lists & count lines (for y_train!)\n",
    "corpus_seawolf = [sentence for chapter in seawolf_chapters for sentence in chapter]\n",
    "len(corpus_seawolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "210114a2-f459-4631-82b8-ac9aa4b247af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1955"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten lists & count lines (for y_train!)\n",
    "corpus_mobydick = [sentence for chapter in mobydick_chapters for sentence in chapter]\n",
    "len(corpus_mobydick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b92373c7-6583-4bc2-b02e-91bb7f82b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corpus for BoW\n",
    "corpus = corpus_seawolf.copy() # copy of corpus_seawolf (deep copy)\n",
    "# corpus = corpus_seawolf is not good, beacuse lists are mutable (shallow copy)\n",
    "corpus.extend(corpus_mobydick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70180db-408e-4c49-a751-3f589e7acedb",
   "metadata": {},
   "source": [
    "## Test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "50728a19-da14-4da8-bba0-944a5757502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1afc8788-a117-4d08-8ef7-e2c95371dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts.append(\"\"\"Louis has also given me additional information about Death Larsen, which\n",
    "tallies with the captain’s brief description.\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6f5ea28b-483b-4bd2-b0ca-a1d4a51ff534",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts.append(\"\"\"Be it said, that\n",
    "though I had felt such a strong repugnance to his smoking in the bed\n",
    "the night before, yet see how elastic our stiff prejudices grow when\n",
    "love once comes to bend them.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "323379fb-757d-4f79-b055-ce2956ef4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts.append(\"\"\"To crawl is piggish; but to not crawl, to be as\n",
    "the clod and rock, is loathsome to contemplate.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "77f4ebed-421b-4a4e-91d9-b8496d1177cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts.append(\"\"\"Upon opening my eyes then, and coming\n",
    "out of my own pleasant and self-created darkness into the imposed and\n",
    "coarse outer gloom of the unilluminated twelve-o'clock-at-night, I\n",
    "experienced a disagreeable revulsion.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07218b54-2556-4587-8c1c-78062c842967",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts.append(\"\"\"For the Preacher loved life, and did\n",
    "not want to die, saying, ‘For a living dog is better than a dead lion.’\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f76efd-f5ac-4e94-bdc9-3d7458341405",
   "metadata": {},
   "source": [
    "### Seawolf = 1 ; Moby-Dick = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "10109b9b-9c4a-46f7-a32d-b4c72024581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.Series([1] * 3038 + [0] * 1955)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4589902-04f2-4fb4-9400-f2a9c6360589",
   "metadata": {},
   "source": [
    "## Manual feature extraction (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1a36fc68-281d-437a-964f-24d0bacc6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlists = []\n",
    "# get words out of sentences and do some processing (lower case, word selection,...)\n",
    "for sentence in corpus:\n",
    "    text = re.findall(r'[A-Za-z+]{4,}', sentence)\n",
    "    wordlists.append([word.lower() for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6dc80741-9104-4aa8-8630-7878080cb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list\n",
    "wordset = [word for sentence in wordlists for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "47557b2d-ea8e-4730-ac0a-dec5995081f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26889"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "743f150c-73a8-4682-870b-80ad87c7419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique set of words (columns in doc-term matrix)\n",
    "wordset = sorted(list(set(wordset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e9dce150-19e4-40d0-bc94-7c399a698363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6826"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bb3a0fbf-64bc-4ee8-8119-19d3a871edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate entry in Bag of Words doc-term matrix\n",
    "def calculate_bag_of_words(wordset, sentence):\n",
    "    tf_dict = dict.fromkeys(wordset, 0)\n",
    "    for word in sentence:\n",
    "        if word not in wordset:\n",
    "            continue\n",
    "        tf_dict[word] = sentence.count(word)\n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f8037674-3e74-4c6b-b4ea-6bd46e2f1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = [calculate_bag_of_words(wordset, sentence) for sentence in wordlists]\n",
    "df_bow = pd.DataFrame(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62b81344-b6bf-4d3e-b360-7b42b5d6d439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abed</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>able</th>\n",
       "      <th>ablutions</th>\n",
       "      <th>aboard</th>\n",
       "      <th>...</th>\n",
       "      <th>yonson</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youth</th>\n",
       "      <th>yted</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zephyr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4993 rows × 6826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aback  abandon  abandoned  abbreviated  abdomen  abed  ablaze  able  \\\n",
       "0         0        0          0            0        0     0       0     0   \n",
       "1         0        0          0            0        0     0       0     0   \n",
       "2         0        0          0            0        0     0       0     0   \n",
       "3         0        0          0            0        0     0       0     0   \n",
       "4         0        0          0            0        0     0       0     0   \n",
       "...     ...      ...        ...          ...      ...   ...     ...   ...   \n",
       "4988      0        0          0            0        0     0       0     0   \n",
       "4989      0        0          0            0        0     0       0     0   \n",
       "4990      0        0          0            0        0     0       0     0   \n",
       "4991      0        0          0            0        0     0       0     0   \n",
       "4992      0        0          0            0        0     0       0     0   \n",
       "\n",
       "      ablutions  aboard  ...  yonson  young  your  yours  yourself  youth  \\\n",
       "0             0       0  ...       0      0     0      0         0      0   \n",
       "1             0       0  ...       0      0     0      0         0      0   \n",
       "2             0       0  ...       0      0     0      0         0      0   \n",
       "3             0       0  ...       0      0     0      0         0      0   \n",
       "4             0       0  ...       0      0     0      0         0      0   \n",
       "...         ...     ...  ...     ...    ...   ...    ...       ...    ...   \n",
       "4988          0       0  ...       0      0     0      0         0      0   \n",
       "4989          0       0  ...       0      0     0      0         0      0   \n",
       "4990          0       0  ...       0      0     0      0         0      0   \n",
       "4991          0       0  ...       0      0     0      0         0      0   \n",
       "4992          0       0  ...       0      0     0      0         0      0   \n",
       "\n",
       "      yted  zealand  zephyr  zone  \n",
       "0        0        0       0     0  \n",
       "1        0        0       0     0  \n",
       "2        0        0       0     0  \n",
       "3        0        0       0     0  \n",
       "4        0        0       0     0  \n",
       "...    ...      ...     ...   ...  \n",
       "4988     0        0       0     0  \n",
       "4989     0        0       0     0  \n",
       "4990     0        0       0     0  \n",
       "4991     0        0       0     0  \n",
       "4992     0        0       0     0  \n",
       "\n",
       "[4993 rows x 6826 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535a4a6-d719-4763-a021-e3e8d3e9d109",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c65ef765-7945-4c75-9b18-86d1e3444cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_manual = LogisticRegression()\n",
    "logreg_manual.fit(df_bow ,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e4e497b1-77a2-4ccc-951a-4cc82121564b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930702984177849"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_manual.score(df_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "33ed1238-925b-4166-95b6-a7860edbe12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_wordlists = []\n",
    "for sentence in test_texts:\n",
    "    text = re.findall(r'[A-Za-z+]{4,}', sentence)\n",
    "    X_test_wordlists.append([word.lower() for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ec942c-e109-4c6b-99c8-3a5f6832ab41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_wordlists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ca98753c794e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcalculate_bag_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test_wordlists\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_wordlists' is not defined"
     ]
    }
   ],
   "source": [
    "X_test = [calculate_bag_of_words(wordset, sentence) for sentence in X_test_wordlists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac894aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0c1cdefd54ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "118b4766-e911-4efc-a1da-694fc8025aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e80883bc-3788-4f70-8a94-47a265933643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abed</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>able</th>\n",
       "      <th>ablutions</th>\n",
       "      <th>aboard</th>\n",
       "      <th>...</th>\n",
       "      <th>yonson</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youth</th>\n",
       "      <th>yted</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zephyr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aback  abandon  abandoned  abbreviated  abdomen  abed  ablaze  able  \\\n",
       "0      0        0          0            0        0     0       0     0   \n",
       "1      0        0          0            0        0     0       0     0   \n",
       "2      0        0          0            0        0     0       0     0   \n",
       "3      0        0          0            0        0     0       0     0   \n",
       "4      0        0          0            0        0     0       0     0   \n",
       "\n",
       "   ablutions  aboard  ...  yonson  young  your  yours  yourself  youth  yted  \\\n",
       "0          0       0  ...       0      0     0      0         0      0     0   \n",
       "1          0       0  ...       0      0     0      0         0      0     0   \n",
       "2          0       0  ...       0      0     0      0         0      0     0   \n",
       "3          0       0  ...       0      0     0      0         0      0     0   \n",
       "4          0       0  ...       0      0     0      0         0      0     0   \n",
       "\n",
       "   zealand  zephyr  zone  \n",
       "0        0       0     0  \n",
       "1        0       0     0  \n",
       "2        0       0     0  \n",
       "3        0       0     0  \n",
       "4        0       0     0  \n",
       "\n",
       "[5 rows x 6826 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1df99a99-3968-4307-a184-54d09a862c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_manual.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "23eacb7f-e982-4617-9944-aea62de1a1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00441198, 0.99558802],\n",
       "       [0.65968954, 0.34031046],\n",
       "       [0.07079281, 0.92920719],\n",
       "       [0.95427309, 0.04572691],\n",
       "       [0.07370315, 0.92629685]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_manual.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb58620-82b9-4201-9fcf-dd0e5f21f39a",
   "metadata": {},
   "source": [
    "## Sklearn CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ae51c586-0b3f-4d3c-8e0c-1fd874e84ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abed</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>able</th>\n",
       "      <th>ablutions</th>\n",
       "      <th>aboard</th>\n",
       "      <th>...</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>yon</th>\n",
       "      <th>yonder</th>\n",
       "      <th>yonson</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>yted</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zephyr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6869 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aback  abandon  abandoned  abbreviated  abdomen  abed  ablaze  able  \\\n",
       "0      0        0          0            0        0     0       0     0   \n",
       "1      0        0          0            0        0     0       0     0   \n",
       "2      0        0          0            0        0     0       0     0   \n",
       "3      0        0          0            0        0     0       0     0   \n",
       "4      0        0          0            0        0     0       0     0   \n",
       "\n",
       "   ablutions  aboard  ...  yokohama  yon  yonder  yonson  young  youth  yted  \\\n",
       "0          0       0  ...         0    0       0       0      0      0     0   \n",
       "1          0       0  ...         0    0       0       0      0      0     0   \n",
       "2          0       0  ...         0    0       0       0      0      0     0   \n",
       "3          0       0  ...         0    0       0       0      0      0     0   \n",
       "4          0       0  ...         0    0       0       0      0      0     0   \n",
       "\n",
       "   zealand  zephyr  zone  \n",
       "0        0       0     0  \n",
       "1        0       0     0  \n",
       "2        0       0     0  \n",
       "3        0       0     0  \n",
       "4        0       0     0  \n",
       "\n",
       "[5 rows x 6869 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english', token_pattern='[A-Za-z]+', ngram_range=(1,1))\n",
    "X_cv = vectorizer.fit_transform(corpus)\n",
    "df_bow_sklearn = pd.DataFrame(X_cv.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_bow_sklearn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f810188d-a422-4c74-802d-32e5d8a6d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_texts)\n",
    "df_test = pd.DataFrame(X_test.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ca494949-e734-47bb-86e1-5967fb08601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cv = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1e9cee24-7de0-4ce2-b303-1dec888c748c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.fit(df_bow_sklearn, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf37e9d3-f81f-4f54-944d-b367565f9106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319046665331464"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.score(df_bow_sklearn, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eb4e3569-404a-4e10-9923-5447c581966d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0b0985bf-fa42-4b5a-9534-2e7cec57d9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01705228, 0.98294772],\n",
       "       [0.84101127, 0.15898873],\n",
       "       [0.10964161, 0.89035839],\n",
       "       [0.72803982, 0.27196018],\n",
       "       [0.04451704, 0.95548296]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf12eb5-e4a8-45f8-adb7-446c999fa016",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "### Term frequency\n",
    "### Inverse Document frequence\n",
    "$$\\text{tf-idf}(t_i,d_j) = \\frac{f_{t_i,d_j}}{\\sum_{t'\\in d_j}f_{t',d_j}} \\cdot \\Bigl(\\log\\Bigl[{\\frac{N+1}{n_t + 1}\\Bigr]+1}\\Bigr)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1aa6780c-8cb3-46b9-bfd4-4303f79eec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ca9aa340-f9c4-4bf6-8365-e5f4a0870881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf = tfidf.fit_transform(corpus)\n",
    "df_tf = pd.DataFrame(X_tf.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d6b3ad59-5aaf-43e4-b3f1-3f0ca035b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(test_texts)\n",
    "df_test = pd.DataFrame(X_test.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6fd973a1-0016-42a1-9174-b18fa2fe937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_tfidf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "32504d23-4c27-4b93-9ba3-17e9c74d0e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tfidf.fit(df_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "132001b1-92c2-44dc-8869-5954ef2b8aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tfidf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "190ce219-476c-40e9-bdca-933cc019cf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15857505, 0.84142495],\n",
       "       [0.56891604, 0.43108396],\n",
       "       [0.2778443 , 0.7221557 ],\n",
       "       [0.49659482, 0.50340518],\n",
       "       [0.16212461, 0.83787539]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tfidf.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52107b2e-2673-41ac-a042-5170ced4b53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
